
# NaviSearch：Semantic Tags Guided Searching System

## 摘要

本文提出了NaviSearch，一种使用语义标签进行重排序的搜索系统设计。该系统使用双阶段架构，在召回阶段使用预训练嵌入模型进行索引，在重排序阶段使用语义标签进行渐进式过滤，取得了良好的召回与排序精度。该系统可以在LLM的支持下进行无监督的语义标记和渐进式过滤，也能充分利用来自用户的标签体系与过滤提示。本文进行了充分的系统实验，测试了该设计在通信与网络安全行业专业语料上的有效性，并探索了最佳参数配置。

## 引言

大模型缺乏私有知识，且通用知识更新滞后。业界通常采用检索增强生成（RAG）技术，根据用户输入从外部信息源检索相关信息，然后将检索到的内容整合到用户输入中，从而帮助大模型生成更准确的回答。

然而，构建生产可用的RAG系统面临巨大挑战。预训练的嵌入模型与重排模型通常不能理解专业语料中微妙的区别。为了实现更加精准的重排序，通常采用语义标记（Semantic Tagging）技术，使用LLM为检索到的内容生成具有区别性的语义标记，让用户找到最符合需求的信息。

虽然检索时标记（Retrival Time Tagging）能够充分考虑用户意图与召回记录的特点，生成高质量的语义标记，但是这将在召回链路中引入不可靠且高延时的环节。为每一次查询都调用LLM的开销也是不可接受的。插入时标记（Insert Time Tagging）可以预先计算记录被召回时可能使用的标签，将其缓存在标记字段，有效减少了召回延迟，同时拥有可接受的召回质量。

插入时标记依赖于高质量的标记算法，理想的标记算法应当是无监督的，标记语义分布均匀（从宏观到微观连续分布）且可扩展（随着数据规模对数增长）的。

## 相关研究

待补充。

## 方法

NaviSearch使用搜索系统典型的两阶段架构，即召回阶段retrieval stage和重排阶段reranking stage。在召回阶段使用预训练嵌入模型，在重排阶段使用用户或LLM驱动的渐进式过滤。

### 召回

NaviSearch使用阿里云百炼平台提供的Text-Embedding-v3嵌入模型。这是一个预训练稠密文本嵌入模型，可以为文本片段生成256, 512, 768, 1024, 2048维度的稠密语义嵌入向量。本次NaviSearch采用了1024维度的配置。

Text-Embedding-v3通常可以在TOP_50实现高于0.95的召回率，但是平均

### 重排序

NaviSearch使用渐进式过滤机制实现重排序，由用户或LLM生成标签选择信号，促进候选文档规模的缩小。

为了提高交互效率，NaviSearch使用预期信息增益指标对候选文档标签进行排序，并展示TOP_20标签。这种设计有助于迅速缩小候选文档规模的同时，加快用户决策。用户通常可以在TOP_5标签中找到有效的增量标签。另外，用户还可以选择较为罕见但是精确度较高的标签，从而迅速缩小候选文档规模。这通常出现在用户对文档内容已经有一定了解场景。

### 语义标记

语义标记对于NaviSearch系统的性能起到决定性作用。理想状态下，平均每个标签可以减少50%的候选文档规模，但是这在生产场景较难实现，因为标签并不总是正交且平均分割候选文档集合。在实际测试中，平均考虑五个标签可以起到一个理想标签的信息增益。

NaviSearch使用LLM对文档生成语义标签。

## 实验设置

### 标记参数

#### 批次大小

批次大小对于语义标签的质量具有显著影响。

当批次大小为1时，语义标签的质量显著下降。这种情况被称为单文档标记。

当批次大小大于1时，语义标签的质量显著提高，这种情况被称为多文档标记。

随着批次大小增加，语义标签质量迅速提高到较高水平，然后开始缓慢下降，直到触发模型上下文窗口限制。

前者可能是因为提示词促进LLM关注文档之间的区别，从而生成更具区分性的标签。

后者可能是因为过多的文档分散了LLM的注意力，使其对每一个文档关注下降，难以捕获细微的区别。

#### 采样参数

NaviSearch对文档进行标记时，会在语义相似度TOP_K中选择BatchSize个参考文档，组成一个Batch。TOP_K对于生成的标签具有微妙的影响。较小的TOP_K下，LLM倾向于关注相似文档的细微区别，而较大的TOP_K下，LLM倾向于关注宏观的分类概念。该现象可以从标签的覆盖率得到支持。

NaviSearch主要使用语义标签进行相似文档的重排，因此希望标签关注微观和介观概念。建议在TOP_K = BatchSize时进行一次标记，在TOP_K = 16 * BatchSize时进行3次标记，平衡语义标记质量和Token消耗。

#### 标记时机 Timming

##### 召回时标记Retrieval Time Tagging

NaviSearch可以在召回候选文档后进行标记。此时标记的质量较高，因为可以从用户查询语句和标记激活状态中获得提示。

但是召回时标记会引入额外的系统延迟，引入额外的Token消耗，因此仅作为预计算的插入式标记未命中时的fall back策略。

##### 插入时标记Insert Time Tagging

NaviSearch主要采用插入时标记。此时的标记是具有挑战性的，因为缺乏对文档会被如何召回的信息。但是可以通过知识库的其他相似文档猜测该知识库的用途。

NaviSearch将会反复迭代，直到LLM不再提议新的标签为止。

在标记过程中，NaviSearch会维护一个以标签覆盖样本数量为索引的，降序排列的标签列表，同时将TOP_K个标签作为参考标签加入标记提示词。这会轻微损伤最终标签质量，但是可以缩小标签规模（例如为相似概念提出多种类似的表达）的同时加快标签体系的收敛。

如果用户可以提供精心设计的宏观标签体系，那么可以大幅提高最终标签质量。

###

## 评估指标

## 实验结果

## 超参数实验

本算法依赖LLM对语料进行无监督标注。因此研究了LLM生成标记的过程。

### 批次大小

单条标注的质量远低于批次标注。单条标注时，生成的标记在数量、语义分布、表示统一性等方面会显著下降。这可能是因为参考语料突出了特异性的部分，因此可以生成更有代表性的语料。
当批次大小过大时，LLM难以找出具有清晰标注的语义标记，生成的标记质量缓慢下降。
经过研究，当使用deepseek-v3-0324时，语料总长度大于6000，或批次大小大于10时，标记质量下降明显。

### 批次内相似性

批次内部的语义相似性也可能影响语义标记的质量。同一批次记录的语义相似度高，则更倾向于生成微观标记。反之则倾向于生成宏观标记。

由于语义嵌入模型通常在top_200等窗口的召回率较高，因此宏观语义标签并不是必须的。可以在top10进行一次标记，top100中随机进行3次采样，top1000中进行10次采样。生成具有连续语义分布的标签。

## 细节补充

### Record类

Record = {

}
tag_records

2，tag_records(records:List[Record])→List[Dict[str:any]]
调用LLM对一批记录进行打标。当records长度超过batch_size时会告警，并只对前records条记录进行打标。

### Milvus Client

3，Milvus Client
相关连接参数，如MILVUS_URI, MILVUS_TOKEN, MILVUS_COLLECTION_NAME都保存在.env中。
